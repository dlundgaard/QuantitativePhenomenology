{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import traceback\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSTANCES = {\n",
    "    \"MDMA\"              : \"MDMA\",\n",
    "    \"Ketamine\"          : \"Ketamine\",\n",
    "    \"LSD\"               : \"LSD\",\n",
    "    \"Mushrooms\"         : \"Mushrooms\",\n",
    "    \"DMT\"               : \"DMT\",\n",
    "    # \"5-MeO-DMT\"         : \"5MeODMT\",\n",
    "    # \"Mescaline\"         : \"Mescaline\",\n",
    "    # \"Salvia divinorum\"  : \"Salvia_divinorum\",\n",
    "    # \"Oxycodone\"         : \"Oxycodone\",\n",
    "    # \"Alcohol\"           : \"Alcohol\",\n",
    "    # \"Cocaine\"           : \"Cocaine\",\n",
    "    # \"Methamphetamine\"   : \"Methamphetamine\",\n",
    "    # \"Cannabis\"          : \"Cannabis\",\n",
    "}\n",
    "\n",
    "def substance_query(substance):\n",
    "    page = requests.get(f\"\"\"https://erowid.org/experiences/subs/exp_{SUBSTANCES[substance]}.shtml\"\"\")\n",
    "    soup = BeautifulSoup(page.text, \"html5lib\")\n",
    "    url = \"https://erowid.org/\" + [anchor[\"href\"] for anchor in soup.find_all(\"a\", href=True) if \"exp.cgi?S1=\" in anchor[\"href\"]][0]\n",
    "    return url\n",
    "\n",
    "def get_substance_reports(substance):\n",
    "    page = requests.get(substance_query(substance), dict(ShowViews=0, Cellar=0, Start=0, Max=10000)) \n",
    "    soup = BeautifulSoup(page.text, \"html5lib\")\n",
    "    table = soup.find(\"table\", attrs={\"class\": \"exp-list-table\"}).find(\"tbody\")\n",
    "\n",
    "    experience_IDs = []\n",
    "    # for row in table.find_all(\"tr\")[:5]:\n",
    "    for row in table.find_all(\"tr\"):\n",
    "        if row.find(\"td\", attrs={\"class\": \"exp-substance\"}).text.strip().lower() in [key.lower() for key in SUBSTANCES.keys()]:\n",
    "            experience_IDs.append(row.find(\"td\", attrs={\"class\": \"exp-title\"}).find(\"a\", href = True).get(\"href\").split(\"=\")[1])\n",
    "\n",
    "    return experience_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.mount(\n",
    "    \"http://\", \n",
    "    requests.adapters.HTTPAdapter(max_retries=requests.adapters.Retry(\n",
    "        total=5, \n",
    "        backoff_factor=1\n",
    "    ))\n",
    ")\n",
    "\n",
    "def extract_experience_report(experience_ID, verbose = False):\n",
    "    try:\n",
    "        response = requests.get(\"https://erowid.org/experiences/exp.php\", params=dict(ID=experience_ID), timeout=10)\n",
    "        response.raise_for_status()\n",
    "        page_text = response.text\n",
    "        if verbose:\n",
    "            print(\"found page\", page_text)\n",
    "        soup = BeautifulSoup(page_text, \"html5lib\")\n",
    "        if verbose:\n",
    "            print(\"got soup\", soup)\n",
    "        substances = sorted(set([element.getText().strip().lower() for element in soup.find_all(\"td\", {\"class\": \"dosechart-substance\"})])),\n",
    "        if len(substances) > 1:\n",
    "            raise Exception(\"multiple drugs combined\")\n",
    "\n",
    "        data = dict(\n",
    "            experience_ID = experience_ID,\n",
    "            author = soup.find(\"div\", {\"class\": \"author\"}).find(\"a\").getText().strip(),\n",
    "            substance = soup.find(\"td\", {\"class\": \"dosechart-substance\"}).getText().strip(),\n",
    "            content = page_text[page_text.index(\"<!-- Start Body -->\") + len(\"<!-- Start Body -->\"):page_text.index(\"<!-- End Body -->\")].strip(),\n",
    "            time_of_experience = soup.find(\"td\", {\"class\": \"footdata-expyear\"}).getText().split(\":\")[1].strip(),\n",
    "            time_of_submission = soup.find(\"td\", {\"class\": \"footdata-pubdate\"}).getText().split(\":\")[1].strip(),\n",
    "            age_at_experience = soup.find(\"td\", {\"class\": \"footdata-ageofexp\"}).getText().split(\":\")[1].strip(),\n",
    "            gender = soup.find(\"td\", {\"class\": \"footdata-gender\"}).getText().split(\":\")[1].strip().lower(),\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(time.strftime(\"%H:%M:%S\"), experience_ID)\n",
    "            print(data[\"substance\"])\n",
    "            print(data[\"content\"])\n",
    "            print(\" \".join(data[\"content\"].split(\"\\n\")[:5]))\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Experience {experience_ID}\")\n",
    "        print(type(e).__name__)\n",
    "        # print(traceback.format_exc())\n",
    "\n",
    "# reports = [extract_experience_report(experience_ID) for substance in SUBSTANCES for experience_ID in tqdm.tqdm(get_substance_reports(substance), desc = substance)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "# df = pd.read_parquet(\"data/database.parquet\")\n",
    "for substance in reversed(SUBSTANCES.keys()):\n",
    "    experience_IDs = get_substance_reports(substance)\n",
    "    reports = []\n",
    "    for idx, experience_ID in enumerate(experience_IDs, start = 1):\n",
    "        print(f\"\"\"[{time.strftime(\"%H:%M:%S\")}] {experience_ID.rjust(6)} ({idx}/{len(experience_IDs)} {substance})\"\"\")\n",
    "        if experience_ID in df[\"experience_ID\"].values:\n",
    "            continue\n",
    "        experience_report = extract_experience_report(experience_ID) \n",
    "        if experience_report:\n",
    "            reports.append(experience_report)\n",
    "        time.sleep(1)\n",
    "    substance_reports = pd.DataFrame.from_records(reports)\n",
    "    df = pd.concat([df, substance_reports], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_parquet(\"data/database.parquet\")\n",
    "df[\"substance\"].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database = df.drop_duplicates(subset = \"experience_ID\")\n",
    "\n",
    "database = pd.read_parquet(\"data/database.parquet\")\n",
    "remapping = {\n",
    "    \"Mushrooms\"         : \"Psilocybin\",\n",
    "    # \"Salvia divinorum\"  : \"Salvinorin A\",\n",
    "    # \"Cannabis\"          : \"THC\",\n",
    "}\n",
    "database[\"substance\"] = database[\"substance\"].replace(remapping)\n",
    "database[\"gender\"] = database[\"gender\"].str.lower()\n",
    "database[\"gender\"] = database[\"gender\"].str.strip()\n",
    "database = database[database[\"substance\"].isin(list(SUBSTANCES.keys()) + list(remapping.values()))]\n",
    "\n",
    "database.to_parquet(\"data/database.parquet\")\n",
    "print(f\"\"\"{len(database[\"substance\"])} experience reports\"\"\")\n",
    "database[\"substance\"].value_counts(dropna = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_kernel",
   "language": "python",
   "name": "venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
